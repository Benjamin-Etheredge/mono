---
apiVersion: source.toolkit.fluxcd.io/v1
kind: HelmRepository
metadata:
  name: ollama-helm
  namespace: ollama
spec:
  interval: 30m0s
  url: https://otwld.github.io/ollama-helm/
---
apiVersion: helm.toolkit.fluxcd.io/v2
kind: HelmRelease
metadata:
  name: ollama
  namespace: ollama
spec:
  interval: 5m0s
  # increasing timeout for model pulling
  timeout: 30m
  chart:
    spec:
      chart: ollama
      reconcileStrategy: ChartVersion
      sourceRef:
        kind: HelmRepository
        name: ollama-helm
      version: 1.2.0
  values:
    ollama:
      gpu:
        enabled: true
        type: 'nvidia'
        number: 1
      models:
        insecure: true
        pull:
          - llama3.2
          - nomic-embed-text
          - qwen2.5-coder:14b
          - qwen2.5-coder:32b
          - deepseek-r1:14b
          - deepseek-r1:32b
          - deepseek-r1:70b
    persistentVolume:
      enabled: true
      size: 200Gi
      storageClass: "nfs-csi"
    ingress:
      enabled: true
      annotations:
        nginx.ingress.kubernetes.io/proxy-body-size: "4096m"
        nginx.ingress.kubernetes.io/proxy-read-timeout: "3600"
      hosts:
        # - host: ollama.etheredge.dev
        #   paths:
        #     - path: /
        #       pathType: Prefix
        - host: ollama.k8s.lan
          paths:
            - path: /
              pathType: Prefix
